{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python import\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Our custom module\n",
    "sys.path.append('../')\n",
    "import data_processing\n",
    "import models\n",
    "from evaluation import *\n",
    "import submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma proposition : \n",
    "Avoir un Notebook template associé à des paramètres par défaut. \n",
    "Ensuite pour chaque expérience on le duplique, et on change les valeurs des paramètres que l'on souhaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/default_params.yaml') as default_params_file:\n",
    "      default_params = yaml.safe_load(default_params_file)\n",
    "params = default_params\n",
    "params\n",
    "\n",
    "data_dir = os.path.join('..','data')\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changer de paramètres\n",
    "params[\"train\"][\"batch_size\"] = 1\n",
    "params[\"train\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export masks as .tiff files\n",
    "\n",
    "If it's the first time you run this notebook, you should uncomment the following cell and run it. It will read the masks from the .csv file and output them as .tiff files in a \"train_masks\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.preproc import create_masks_as_tiff, preprocess_images_and_masks\n",
    "\n",
    "# create_masks_as_tiff(data_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.utils import get_training_datasets_and_dataloaders\n",
    "\n",
    "train_dataset, validation_dataset, train_dataloader, validation_dataloader = get_training_datasets_and_dataloaders(batch_size=params[\"train\"][\"batch_size\"] ,input_size=1024)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "\n",
    "MODEL = UNet(num_classes=1).to(device)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(MODEL.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.train import main_train, main_train_batch1\n",
    "\n",
    "if params[\"train\"][\"batch_size\"] == 1:\n",
    "    loss_list = main_train_batch1(model=MODEL.to(device), loss_fn=loss, optimizer=optimizer, n_epochs=25, dataset=train_dataset, device=device)\n",
    "if params[\"train\"][\"batch_size\"] > 1:\n",
    "    loss_list = main_train(model=MODEL.to(device), loss_fn=loss, optimizer=optimizer, n_epochs=25, dataloader=train_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_mask(image,mask,cmaps):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(16, 32))\n",
    "    hybr = image[0, :, :]/2 + mask[0, :, :]\n",
    "\n",
    "    ax[0].imshow(image.T)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('IMAGE')\n",
    "    ax[1].imshow(hybr.T,cmap=cmaps)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('MASK ON IMAGE')\n",
    "    plt.show()\n",
    "\n",
    "image, _, mask = train_dataset[0]\n",
    "\n",
    "show_image_and_mask(image,mask,\"gray\")\n",
    "show_image_and_mask(image,MODEL(torch.unsqueeze(image, dim=0).to(device)).cpu().detach(),\"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "torch.save(MODEL, f\"../model_save/save_{datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Running model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_pred = {\"val_images\":[], \"val_masks\":[], \"val_organs\":[], \"val_y_preds\":[]}\n",
    "# for k, (val_image, val_organ, val_mask) in enumerate(train_dl):\n",
    "#     print(k)\n",
    "#     val_pred['val_images'].append(val_image)\n",
    "#     val_pred['val_masks'].append(val_mask)\n",
    "#     val_pred['val_organs'].append(val_organ)\n",
    "\n",
    "#     gc.collect()\n",
    "#     print(torch.cuda.memory_allocated(0),\n",
    "#         torch.cuda.memory_reserved(0),\n",
    "#         torch.cuda.max_memory_reserved(0),)\n",
    "#     pred = MODEL(val_image.to(device))\n",
    "#     val_pred['val_y_preds'].append(pred.cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation images, masks and organs\n",
    "val_preds = {0:{\"val_images\":[], \"val_masks\":[], \"val_organs\":[], \"val_y_preds\":[]}} #Only 1 fold\n",
    "\n",
    "for l, batch in enumerate(validation_dataloader):\n",
    "    (val_images, val_organs, val_masks) = next(iter(train_dataloader))\n",
    "    val_mask_preds = MODEL(val_images.to(device)).cpu().detach()\n",
    "    print(f'VAL_Y_PREDS shape: {val_mask_preds.shape}, VAL_Y_PREDS dtype: {val_mask_preds.dtype}')\n",
    "    print(f'val_images shape: {val_images.shape}, val_masks shape: {val_masks.shape}, val_organs shape: {len(val_organs)}')\n",
    "    for k in range(len(val_images)):\n",
    "        # Cast from Tensorflow to Numpy\n",
    "        val_preds[0]['val_images'].append(val_images[k].numpy())\n",
    "        val_preds[0]['val_masks'].append(val_masks[k].numpy().astype(np.uint8))\n",
    "        val_preds[0]['val_organs'].append(val_organs[k])\n",
    "        val_preds[0]['val_y_preds'].append(val_mask_preds[k].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "print(torch.cuda.memory_allocated(0),\n",
    "      torch.cuda.memory_reserved(0),\n",
    "    torch.cuda.max_memory_reserved(0),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluation import get_y_true_y_pred\n",
    "\n",
    "IoU_Folds = dict()\n",
    "for fold, v in val_preds.items():\n",
    "    IoUs, IoUsOrgans = get_y_true_y_pred(v)\n",
    "    IoU_Folds[fold] = {\n",
    "        'IoUs': IoUs,\n",
    "        'IoUsOrgans': IoUsOrgans,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluation import plot_iou_by_threshold\n",
    "\n",
    "# Global Mean Intersection over Union at Threshold\n",
    "for fold, v in IoU_Folds.items():\n",
    "    print('=' * 80)\n",
    "    print(f'FOLD {fold}')\n",
    "    print('=' * 80)\n",
    "    v['threshold_best'] = plot_iou_by_threshold(v['IoUs'], f'all_{fold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, v in IoU_Folds.items():\n",
    "    print('=' * 80)\n",
    "    print(f'FOLD {fold}')\n",
    "    print('=' * 80)\n",
    "\n",
    "    percentiles = [0.01, 0.05, 0.10, 0.25, 0.40, 0.50, 0.60, 0.75, 0.90, 0.95, 0.99]\n",
    "    s = v['IoUs'][v['threshold_best']]\n",
    "\n",
    "    display(pd.Series(s).describe(percentiles=percentiles).apply(lambda v: f'{v:.2f}').to_frame(name='Value').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, v in IoU_Folds.items():\n",
    "    print('=' * 80)\n",
    "    print(f'FOLD {fold}')\n",
    "    print('=' * 80)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    pd.Series(v['IoUs'][v['threshold_best']]).plot(kind='hist')\n",
    "    plt.title('IoU Distribution at Best Threshold', size=24)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Threshold', size=16)\n",
    "    plt.ylabel('Count', size=16)\n",
    "    plt.xticks(size=12)\n",
    "    plt.yticks(size=12)\n",
    "    plt.xlim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluation import plot_validation_predictions\n",
    "\n",
    "for fold, v in IoU_Folds.items():\n",
    "    print('=' * 80)\n",
    "    print(f'FOLD {fold}')\n",
    "    print('=' * 80)\n",
    "    threshold_best = IoU_Folds[fold]['threshold_best']\n",
    "    plot_validation_predictions(val_preds[fold], threshold_best, 2, IoUs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission import submission\n",
    "\n",
    "test_dataset = None # TO BUILD\n",
    "submission.make_submission(MODEL, test_dataset, threshold_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
