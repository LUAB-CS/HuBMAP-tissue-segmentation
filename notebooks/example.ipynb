{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python import\n",
    "import sys\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pytorch\n",
    "from torch.utils.data import DataLoader\n",
    "import optim\n",
    "import torch.nn\n",
    "\n",
    "# Our custom module\n",
    "sys.path.append('../')\n",
    "import data_processing\n",
    "import models\n",
    "import evaluation as eval\n",
    "import submission as sub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma proposition : \n",
    "Avoir un Notebook template associé à des paramètres par défaut. \n",
    "Ensuite pour chaque expérience on le duplique, et on change les valeurs des paramètres que l'on souhaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_title': 'write here the purpose of your experiment',\n",
       " 'dataset': {'script_path': '../data_processing/A_COMPLETER.py'},\n",
       " 'model': {'script_path': '../models/A_COMPLETER.py'},\n",
       " 'optimizer': {'script_path': '../optimizers/adam_keras.py',\n",
       "  'initial_lr': 0.0001},\n",
       " 'train': {'script_path': '../train/A_COMPLETER.py',\n",
       "  'batch_size': 64,\n",
       "  'epochs': 1000,\n",
       "  'data_augmentation': {'samplewise_center': False,\n",
       "   'samplewise_std_normalization': False,\n",
       "   'rotation_range': 0,\n",
       "   'width_shift_range': 0.1,\n",
       "   'height_shift_range': 0.1,\n",
       "   'horizontal_flip': True,\n",
       "   'vertical_flip': False,\n",
       "   'zoom_range': 0,\n",
       "   'shear_range': 0,\n",
       "   'channel_shift_range': 0,\n",
       "   'featurewise_center': False,\n",
       "   'zca_whitening': False}},\n",
       " 'evaluate': {'batch_size': 1000,\n",
       "  'augmentation_factor': 32,\n",
       "  'data_augmentation': {'samplewise_center': False,\n",
       "   'samplewise_std_normalization': False,\n",
       "   'rotation_range': 0,\n",
       "   'width_shift_range': 0.15,\n",
       "   'height_shift_range': 0.15,\n",
       "   'horizontal_flip': True,\n",
       "   'vertical_flip': False,\n",
       "   'zoom_range': 0,\n",
       "   'shear_range': 0,\n",
       "   'channel_shift_range': 0,\n",
       "   'featurewise_center': False,\n",
       "   'zca_whitening': False}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../configs/default_params.yaml') as default_params_file:\n",
    "      default_params = yaml.safe_load(default_params_file)\n",
    "params = default_params\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'script_path': '../train/A_COMPLETER.py',\n",
       " 'batch_size': 16,\n",
       " 'epochs': 1000,\n",
       " 'data_augmentation': {'samplewise_center': False,\n",
       "  'samplewise_std_normalization': False,\n",
       "  'rotation_range': 0,\n",
       "  'width_shift_range': 0.1,\n",
       "  'height_shift_range': 0.1,\n",
       "  'horizontal_flip': True,\n",
       "  'vertical_flip': False,\n",
       "  'zoom_range': 0,\n",
       "  'shear_range': 0,\n",
       "  'channel_shift_range': 0,\n",
       "  'featurewise_center': False,\n",
       "  'zca_whitening': False}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer de paramètres\n",
    "params[\"train\"][\"batch_size\"] = 16\n",
    "params[\"train\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] Le fichier de pagination est insuffisant pour terminer cette opération. Error loading \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\example.ipynb Cell 5\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdata_processing\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m data_processing\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mCustomDataset(root_dir \u001b[39m=\u001b[39m data_dir)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\__init__.py:128\u001b[0m\n\u001b[0;32m    126\u001b[0m     err \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mWinError(last_error)\n\u001b[0;32m    127\u001b[0m     err\u001b[39m.\u001b[39mstrerror \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Error loading \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdll\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m or one of its dependencies.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    129\u001b[0m \u001b[39melif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     is_loaded \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] Le fichier de pagination est insuffisant pour terminer cette opération. Error loading \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "train_dataset = data_processing.dataset.CustomDataset(root_dir = data_dir)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=2**12, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = models.Unet.Unet(num_classes=2)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(MODEL.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "loss_list = train.train.main_train(model=MODEL, loss_fn=loss, optimizer=optimizer, n_epochs=2, dataloader=train_dl, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Running model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = {\"val_images\":[], \"val_masks\":[], \"val_organs\":[], \"val_y_preds\":[]}\n",
    "for k, X in enumerate(train_dl):\n",
    "    for val_image, val_mask, val_organ in X :\n",
    "        val_pred['val_images'].append(val_image)\n",
    "        val_pred['val_mask'].append(val_mask)\n",
    "        val_pred['val_organ'].append(val_organ)\n",
    "        pred = MODEL(val_image)\n",
    "        val_pred['val_y_preds'].append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoUs, IoUsOrgans = eval.get_y_true_y_pred(val_pred)\n",
    "\n",
    "# Plot results for different threshold on all training and get best threshold\n",
    "best_threshold = eval.plot_iou_by_threshold(IoUs, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.plot_validation_predictions(val_pred, best_threshold, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import submission as sub\n",
    "\n",
    "test_dataset = None\n",
    "sub.make_submission(MODEL, test_dataset, best_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
