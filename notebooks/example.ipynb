{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Basic python import\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Our custom module\n",
    "sys.path.append('../')\n",
    "import data_processing\n",
    "import models\n",
    "import evaluation \n",
    "import submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ma proposition : \n",
    "Avoir un Notebook template associé à des paramètres par défaut. \n",
    "Ensuite pour chaque expérience on le duplique, et on change les valeurs des paramètres que l'on souhaite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/default_params.yaml') as default_params_file:\n",
    "      default_params = yaml.safe_load(default_params_file)\n",
    "params = default_params\n",
    "params\n",
    "\n",
    "data_dir = os.path.join('..','data')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'script_path': '../train/A_COMPLETER.py',\n",
       " 'batch_size': 2,\n",
       " 'epochs': 1000,\n",
       " 'data_augmentation': {'samplewise_center': False,\n",
       "  'samplewise_std_normalization': False,\n",
       "  'rotation_range': 0,\n",
       "  'width_shift_range': 0.1,\n",
       "  'height_shift_range': 0.1,\n",
       "  'horizontal_flip': True,\n",
       "  'vertical_flip': False,\n",
       "  'zoom_range': 0,\n",
       "  'shear_range': 0,\n",
       "  'channel_shift_range': 0,\n",
       "  'featurewise_center': False,\n",
       "  'zca_whitening': False}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changer de paramètres\n",
    "params[\"train\"][\"batch_size\"] = 2\n",
    "params[\"train\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If necessary, pre-process raw data (to do once on each machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.preproc import create_masks_as_tiff, preprocess_images_and_masks\n",
    "\n",
    "# create_masks_as_tiff(data_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing.dataset import CustomDataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512,512))\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(root_dir = os.path.join('..','data'), transform=transform)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=params[\"train\"][\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: False\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.unet import UNet\n",
    "\n",
    "MODEL = UNet(num_classes=1)\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(MODEL.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/176 [00:14<42:34, 14.60s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 108000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\example.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m main_train\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_list \u001b[39m=\u001b[39m main_train(model\u001b[39m=\u001b[39;49mMODEL\u001b[39m.\u001b[39;49mto(device), loss_fn\u001b[39m=\u001b[39;49mloss, optimizer\u001b[39m=\u001b[39;49moptimizer, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, dataloader\u001b[39m=\u001b[39;49mtrain_dl, device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\..\\train\\train.py:22\u001b[0m, in \u001b[0;36mmain_train\u001b[1;34m(model, loss_fn, optimizer, n_epochs, dataloader, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m start_time_epoch \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     20\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m X, organ, y \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m     23\u001b[0m     \u001b[39m# 1. Forward pass\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     model_output \u001b[39m=\u001b[39m model(X\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     26\u001b[0m     \u001b[39m# 2. Calculate and accumulate loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\..\\data_processing\\dataset.py:27\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     25\u001b[0m organ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta_df[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_files[idx][:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])][\u001b[39m\"\u001b[39m\u001b[39morgan\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     image_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image)\n\u001b[0;32m     28\u001b[0m     label_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(label)\n\u001b[0;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m (image_tensor, organ, label_tensor)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:152\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39m# backward compatibility\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 108000000 bytes."
     ]
    }
   ],
   "source": [
    "from train.train import main_train\n",
    "\n",
    "loss_list = main_train(model=MODEL.to(device), loss_fn=loss, optimizer=optimizer, n_epochs=1, dataloader=train_dl, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Running model on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_10600\\2975505128.py\", line 2, in <module>\n",
      "    for k, (val_image, val_organ, val_mask) in enumerate(train_dl):\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 58, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"c:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\..\\data_processing\\dataset.py\", line 23, in __getitem__\n",
      "    image = tifffile.imread(image_path)\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\tifffile\\tifffile.py\", line 819, in imread\n",
      "    return tif.asarray(**kwargs)\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\tifffile\\tifffile.py\", line 3226, in asarray\n",
      "    result = self.filehandle.read_array(\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\site-packages\\tifffile\\tifffile.py\", line 9674, in read_array\n",
      "    result = numpy.empty(count, dtype) if out is None else out\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 25.7 MiB for an array with shape (27000000,) and data type uint8\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 793, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 848, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 323, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 247, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 275, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, lines)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 285, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 95, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"C:\\Users\\bapti\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "  File \"c:\\Users\\bapti\\miniconda3\\lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "val_pred = {\"val_images\":[], \"val_masks\":[], \"val_organs\":[], \"val_y_preds\":[]}\n",
    "for k, (val_image, val_organ, val_mask) in enumerate(train_dl):\n",
    "    val_pred['val_images'].append(val_image)\n",
    "    val_pred['val_mask'].append(val_mask)\n",
    "    val_pred['val_organ'].append(val_organ)\n",
    "    pred = MODEL(val_image)\n",
    "    val_pred['val_y_preds'].append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'evaluation' has no attribute 'get_y_true_y_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bapti\\Documents\\Cours3A\\DL\\HuBMAP-tissue-segmentation\\notebooks\\example.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m IoUs, IoUsOrgans \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mget_y_true_y_pred(val_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Plot results for different threshold on all training and get best threshold\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bapti/Documents/Cours3A/DL/HuBMAP-tissue-segmentation/notebooks/example.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m best_threshold \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mplot_iou_by_threshold(IoUs, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'evaluation' has no attribute 'get_y_true_y_pred'"
     ]
    }
   ],
   "source": [
    "IoUs, IoUsOrgans = evaluation.get_y_true_y_pred(val_pred)\n",
    "\n",
    "# Plot results for different threshold on all training and get best threshold\n",
    "best_threshold = evaluation.plot_iou_by_threshold(IoUs, 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_validation_predictions(val_pred, best_threshold, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = None\n",
    "submission.make_submission(MODEL, test_dataset, best_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
